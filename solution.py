# -*- coding: utf-8 -*-
"""solution.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ig3ivCmO-NLqDS9G5NympS3dXamvqmRD
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Train data
train = pd.read_csv('train_data.csv')
train.head(n=10)

# Test data
test = pd.read_csv('data_for_test.csv')
test.head(n=10)

#check that there are no missing values in either training set
print('The dataset has', train.isna().sum().sum(), 'missing values in train data.')
print('The dataset has', test.isna().sum().sum(), 'missing values in test data.')

# check if there are any duplicates
print('The dataset has', train.duplicated().sum(), 'duplicates in train data.')
print('The dataset has', test.duplicated().sum(), 'duplicates in test data.')

# remove duplicates in train data
train.drop_duplicates(subset=['title', 'data'], inplace=True)

# remove duplicates in test data
test.drop_duplicates(subset=['data'], inplace=True)

"""**DATA PREPROCESSING**"""



X_train, y_train = train['data'], train['title']
X_test = test['data']

"""

*   *Transforming text to a vector*
*Creating tf-idf feature


*   encode labels
*   compute tf-idf

https://www.kaggle.com/roccoli/multi-label-classification-with-sklearn



"""

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MultiLabelBinarizer
# create a count vectorizer object
count_vect = CountVectorizer(analyzer='word', token_pattern=r'\w{1,}')
count_vect.fit(X_train)
# Transform documents to document-term matrix.
X_train_count = count_vect.transform(X_train)
X_test_count = count_vect.transform(X_test)

# preprocessing
multilabel_binarizer = MultiLabelBinarizer()
multilabel_binarizer.fit(y_train)
Y = multilabel_binarizer.transform(y_train)

tfidf_vect = TfidfVectorizer(analyzer='word', max_features=90000)
tfidf_vect.fit(X_train) # learn vocabulary and idf from training set
X_data_tfidf = tfidf_vect.transform(X_train)
# giả sử không có tập test trước đó 
X_test_tfidf = tfidf_vect.transform(X_test)

y_train

"""**Training a classifier**"""

from sklearn.naive_bayes import MultinomialNB, BernoulliNB
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score

def train_model(classifier, X_train, y_train, X_test):           
    classifier.fit(X_train, y_train)
    train_predictions = classifier.predict(X_train)
    test_predictions = classifier.predict(X_test)        
    print("Training accuracy: ", accuracy_score(train_predictions, y_train))    

    return test_predictions

"""**Result 1**"""

result = train_model(SGDClassifier(), X_data_tfidf, y_train, X_test_tfidf)

len(result)

import csv
file = './nhom10_AD_SOL1.txt'
with open(file, 'w') as f:
    for data in result:
        f.writelines(data + "\n")

"""**Result 2**"""

result2 = train_model(MultinomialNB(), X_data_tfidf, y_train, X_test_tfidf)

len(result2)

file = './nhom10_AD_SOL2.txt'
with open(file, 'w') as f:
    for data in result2:
        f.writelines(data + "\n")

"""**Result 3**"""

from sklearn.neighbors import NearestCentroid
result3 = train_model(NearestCentroid(), X_data_tfidf, y_train, X_test_tfidf)

file = './nhom10_AD_SOL3.txt'
with open(file, 'w') as f:
    for data in result3:
        f.writelines(data + "\n")

"""**Result 4**"""

from sklearn.multiclass import OneVsRestClassifier
result4 = train_model(OneVsRestClassifier(SGDClassifier()), X_data_tfidf, y_train, X_test_tfidf)

file = './nhom10_AD_SOL4.txt'
with open(file, 'w') as f:
    for data in result4:
        f.writelines(data + "\n")

"""**Result 5**"""

result5 = train_model(OneVsRestClassifier(MultinomialNB()), X_data_tfidf, y_train, X_test_tfidf)

file = './nhom10_AD_SOL5.txt'
with open(file, 'w') as f:
    for data in result5:
        f.writelines(data + "\n")